{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from ultralytics.utils import TQDM\n",
    "from ultralytics.utils.files import increment_path\n",
    "from ultralytics.data.converter import merge_multi_segment\n",
    "import zipfile\n",
    "import os\n",
    "import yaml\n",
    "import shutil\n",
    "import traceback\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_path = \"/vol/bitbucket/ajm223/SWE_GP/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Synth COCO zip file into a YOLO suitable dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_coco(\n",
    "    labels_dir=\"../coco/annotations/\",\n",
    "    save_dir=\"coco_converted/\",\n",
    "    json_file=None,\n",
    "    use_segments=False,\n",
    "    use_keypoints=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Converts COCO dataset annotations to a YOLO annotation format suitable for training YOLO models.\n",
    "\n",
    "    Args:\n",
    "        labels_dir (str, optional): Path to directory containing COCO dataset annotation files.\n",
    "        save_dir (str, optional): Path to directory to save results to.\n",
    "        use_segments (bool, optional): Whether to include segmentation masks in the output.\n",
    "        use_keypoints (bool, optional): Whether to include keypoint annotations in the output.\n",
    "\n",
    "    Example:\n",
    "        ```python\n",
    "        from ultralytics.data.converter import convert_coco\n",
    "\n",
    "        convert_coco('../datasets/coco/annotations/', use_segments=True, use_keypoints=False, cls91to80=True)\n",
    "        ```\n",
    "\n",
    "    Output:\n",
    "        Generates output files in the specified output directory.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create dataset directory\n",
    "    if os.path.exists(save_dir):\n",
    "        shutil.rmtree(save_dir)  # Delete the directory and all its contents\n",
    "\n",
    "    os.makedirs(save_dir)  # Create the directory again\n",
    "    save_dir = Path(save_dir)  # Convert to Path object\n",
    "\n",
    "    for p in save_dir / \"labels\", save_dir / \"images\":\n",
    "        p.mkdir(parents=True, exist_ok=True)  # make dir\n",
    "\n",
    "\n",
    "    # Import json\n",
    "    # for json_file in sorted(Path(labels_dir).resolve().glob(\"*.json\")):\n",
    "    fn = Path(save_dir) / \"labels\"  # folder name\n",
    "    fn.mkdir(parents=True, exist_ok=True)\n",
    "    with open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "        \n",
    "    # Create image dict\n",
    "    images = {f'{x[\"id\"]:d}': x for x in data[\"images\"]}\n",
    "    # Create image-annotations dict\n",
    "    imgToAnns = defaultdict(list)\n",
    "    for ann in data[\"annotations\"]:\n",
    "        imgToAnns[ann[\"image_id\"]].append(ann)\n",
    "\n",
    "    # Write labels file\n",
    "    for img_id, anns in TQDM(imgToAnns.items(), desc=f\"Annotations {json_file}\"):\n",
    "        img = images[f\"{img_id:d}\"]\n",
    "        h, w, f = img[\"height\"], img[\"width\"], img[\"file_name\"]\n",
    "\n",
    "        bboxes = []\n",
    "        segments = []\n",
    "        keypoints = []\n",
    "        for ann in anns:\n",
    "            if ann[\"iscrowd\"]:\n",
    "                continue\n",
    "            # The COCO box format is [top left x, top left y, width, height]\n",
    "            box = np.array(ann[\"bbox\"], dtype=np.float64)\n",
    "            box[:2] += box[2:] / 2  # xy top-left corner to center\n",
    "            box[[0, 2]] /= w  # normalize x\n",
    "            box[[1, 3]] /= h  # normalize y\n",
    "            if box[2] <= 0 or box[3] <= 0:  # if w <= 0 and h <= 0\n",
    "                continue\n",
    "\n",
    "            cls = ann[\"category_id\"]  # class\n",
    "            box = [cls] + box.tolist()\n",
    "            if box not in bboxes:\n",
    "                bboxes.append(box)\n",
    "                if use_segments and ann.get(\"segmentation\") is not None:\n",
    "                    if len(ann[\"segmentation\"]) == 0:\n",
    "                        segments.append([])\n",
    "                        continue\n",
    "                    elif len(ann[\"segmentation\"]) > 1:\n",
    "                        s = merge_multi_segment(ann[\"segmentation\"])\n",
    "                        s = (np.concatenate(s, axis=0) / np.array([w, h])).reshape(-1).tolist()\n",
    "                    else:\n",
    "                        s = [j for i in ann[\"segmentation\"] for j in i]  # all segments concatenated\n",
    "                        s = (np.array(s).reshape(-1, 2) / np.array([w, h])).reshape(-1).tolist()\n",
    "                    s = [cls] + s\n",
    "                    if cls == None:\n",
    "                        print(f\"cls is none for: {img_id}\")\n",
    "                    segments.append(s)\n",
    "                if use_keypoints and ann.get(\"keypoints\") is not None:\n",
    "                    keypoints.append(\n",
    "                        box + (np.array(ann[\"keypoints\"]).reshape(-1, 3) / np.array([w, h, 1])).reshape(-1).tolist()\n",
    "                    )\n",
    "\n",
    "        # Write\n",
    "        file_path = fn / f.split(\"/\")[1]  # Constructs the full path\n",
    "        file_path_with_suffix = file_path.with_suffix(\".txt\")  # Ensures the file has a .txt extension\n",
    "        # Create the parent directories if they don't exist\n",
    "        file_path_with_suffix.parent.mkdir(parents=True, exist_ok=True)   \n",
    "\n",
    "\n",
    "        with open(file_path_with_suffix, \"a\") as file:\n",
    "            for i in range(len(bboxes)):\n",
    "                if use_keypoints:\n",
    "                    line = (*(keypoints[i]),)  # cls, box, keypoints\n",
    "                else:\n",
    "                    line = (\n",
    "                        *(segments[i] if use_segments and len(segments[i]) > 0 else bboxes[i]),\n",
    "                    )  # cls, box or segments\n",
    "                if None not in line:\n",
    "                    file.write((\"%g \" * len(line)).rstrip() % line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ds_dir_name = \"yoloDS5\"\n",
    "\n",
    "# create the new directory\n",
    "new_ds_dir = data_path + new_ds_dir_name\n",
    "os.makedirs(new_ds_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Assuming zip_file is the path to your zip file and data_path is your target directory\n",
    "zip_name = \"synth\"\n",
    "zip_file = data_path + zip_name + \".zip\"\n",
    "unzip_container =  data_path + new_ds_dir_name + \"/\"+ zip_name + \"_dir\"\n",
    "\n",
    "# Create the target directory if it doesn't exist\n",
    "os.makedirs(unzip_container, exist_ok=True)\n",
    "\n",
    "# Unzip the file\n",
    "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "    zip_ref.extractall(unzip_container)\n",
    "\n",
    "\n",
    "# get all the json files in the unzipped directory and move them to the new one\n",
    "for file in os.listdir(unzip_container):\n",
    "    if file.endswith(\".json\"):\n",
    "        os.rename(unzip_container + \"/\" + file, new_ds_dir + \"/\" + file)\n",
    "\n",
    "# now we make da yaml\n",
    "data = {\n",
    "    \"path\": new_ds_dir_name,\n",
    "    \"train\": \"../\" + new_ds_dir_name + \"/train\",\n",
    "    \"val\": \"../\" + new_ds_dir_name + \"/val\",\n",
    "    \"test\": \"../\" + new_ds_dir_name + \"/test\",\n",
    "}\n",
    "\n",
    "\n",
    "with open(f\"{data_path}{new_ds_dir_name}/synth_train.json\", \"r\") as f:\n",
    "    js = json.load(f)\n",
    "\n",
    "\n",
    "\n",
    "# # Update the class names in the data structure\n",
    "data[\"names\"] = {cat[\"id\"]: cat[\"name\"] for cat in js[\"categories\"]}\n",
    "\n",
    "# move the unzipped files to the new directory\n",
    "yaml_file_path = f\"{new_ds_dir}/{new_ds_dir_name}.yaml\"\n",
    "with open(yaml_file_path, 'w') as file:\n",
    "    yaml.safe_dump(data, file, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "\n",
    "# here we create the yolo labels for each set using the corresponding jsons, remember, the synth dataset is the train set\n",
    "convert_coco(labels_dir=new_ds_dir + \"synth\",save_dir=new_ds_dir + \"/train\", json_file= f\"{new_ds_dir}/synth_train.json\" , use_segments=True)\n",
    "convert_coco(labels_dir=new_ds_dir + \"val\",save_dir=new_ds_dir + \"/val\", json_file= f\"{new_ds_dir}/synth_val.json\" , use_segments=True)\n",
    "convert_coco(labels_dir=new_ds_dir + \"test\",save_dir=new_ds_dir + \"/test\", json_file= f\"{new_ds_dir}/test.json\" , use_segments=True)\n",
    "\n",
    "# now we need to move the images from the unzip container to the correct folder so they correspond to the labels\n",
    "\n",
    "# for the train set, simply rename the entire synth images folder\n",
    "train_images_dir = new_ds_dir + \"/train/images\"\n",
    "if os.path.exists(train_images_dir) and os.listdir(train_images_dir):\n",
    "    shutil.rmtree(train_images_dir)\n",
    "os.rename(unzip_container + \"/synth_train_images\", train_images_dir)\n",
    "\n",
    "# do the same for the synth val set\n",
    "val_images_dir = new_ds_dir + \"/val/images\"\n",
    "if os.path.exists(val_images_dir) and os.listdir(val_images_dir):\n",
    "    shutil.rmtree(val_images_dir)\n",
    "os.rename(unzip_container + \"/synth_val_images\", val_images_dir)\n",
    "\n",
    "# we need to do the test set differently since the images arent isolated in their folder\n",
    "with open(f\"{new_ds_dir}/test.json\", \"r\") as f:\n",
    "    js = json.load(f)\n",
    "    for img in js[\"images\"]:\n",
    "        os.rename(unzip_container + \"/images/\" + img[\"file_name\"].split(\"/\")[1], new_ds_dir + \"/test/images/\" + img[\"file_name\"].split(\"/\")[1])\n",
    "\n",
    "\n",
    "# remove the unzipped container\n",
    "shutil.rmtree(unzip_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n-seg.pt')  # load the pretrained yolo seg model model (recommended for training)\n",
    "\n",
    "# Train the model -> you reckon this imgsz thing works?\n",
    "ts = 5\n",
    "\n",
    "try:\n",
    "    \n",
    "    results = model.train(data=f'../../data/yoloDS{ts}/yoloDS{ts}.yaml', epochs=200, imgsz=1000, device = 0, batch = -1)\n",
    "except Exception as e:\n",
    "\n",
    "    with open(\"error.txt\", \"a\") as f:\n",
    "        f.write(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.models.yolo.segment import SegmentationValidator\n",
    "ts =3\n",
    "\n",
    "args = dict(model='../../runs/segment/train22/weights/best.pt', data=f'../../data/yoloDS{ts}/seed-seg-ds{ts}.yaml')\n",
    "validator = SegmentationValidator(args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.plot_val_samples(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print attributes of model\n",
    "print([a for a in dir(model2) if not a.startswith(\"__\")])\n",
    "print(model2.trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model2 = YOLO('/vol/bitbucket/ajm223/SWE_GP/runs/segment/train22/weights/best.pt') # build from YAML and transfer weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model2.val()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(result[0].save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n =1\n",
    "ints = np.random.choice(range(0,2000 ), replace = False, size = n)\n",
    "\n",
    "\n",
    "image_path = data_path + \"/yoloDS3/val/images/\"\n",
    "image_files = os.listdir(image_path)\n",
    "\n",
    "img_paths = [image_path + image_files[i] for i in ints]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "result = model2(img_paths)\n",
    "\n",
    "fig, ax = plt.subplots(n, 3, figsize=(30, n*10))\n",
    "\n",
    "plots = [result[i].plot( show=True, boxes = False) for i in range(n)]\n",
    "plots2 = [result[i].plot( show=True, boxes = True, probs = False) for i in range(n)]\n",
    "reals  = [result[i].plot( show=True, boxes = False, masks = False) for i in range(n)]\n",
    "\n",
    "\n",
    "for i in range(n):\n",
    "    ax[i, 0].imshow(plots2[i])\n",
    "    ax[i, 1].imshow(plots[i])\n",
    "    ax[i,2].imshow(reals[i])\n",
    "    # ax[1, 0] = \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[0].boxes)\n",
    "print(result[0].boxes.cls.shape)\n",
    "print(result[0].boxes.xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "\n",
    "model = YOLO('/vol/bitbucket/ajm223/SWE_GP/runs/segment/train22/weights/best.pt')\n",
    "image_path = \"/vol/bitbucket/ajm223/SWE_GP/data/yoloDS3/val/images/\"\n",
    "image_files = os.listdir(image_path)\n",
    "img_paths = [image_path + image_files[i] for i in range(len(image_files))]\n",
    "\n",
    "def pack_results_for_eval(img_paths, output_path, device=\"cpu\"):\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write('[')  # Start of the JSON array\n",
    "        first = True  # Track if the result is the first to avoid leading comma\n",
    "        for img_path in img_paths:\n",
    "            result = list(model(img_path, stream=True))[0]\n",
    "            packed_result = {}\n",
    "            packed_result[\"boxes\"] = result.boxes.xywh.to(device).tolist()\n",
    "            packed_result[\"scores\"] = result.boxes.conf.to(device).tolist()\n",
    "            packed_result[\"masks\"] = result.masks.data.to(torch.bool).to(device).tolist()\n",
    "            packed_result[\"class\"] = result.boxes.cls.to(device).tolist()\n",
    "            \n",
    "            if not first:\n",
    "                f.write(',')  # Add a comma before the next result if it's not the first\n",
    "            else:\n",
    "                first = False  # No comma before the first result\n",
    "            \n",
    "            json.dump(packed_result, f)  # Write the current result as JSON\n",
    "        \n",
    "        f.write(']')  # End of the JSON array\n",
    "\n",
    "output_path = 'incremental_results.json'\n",
    "pack_results_for_eval(img_paths, output_path, device=\"cpu\")\n",
    "print(f\"Results incrementally written to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import os\n",
    "\n",
    "model = YOLO('/vol/bitbucket/ajm223/SWE_GP/runs/segment/train22/weights/best.pt') # build from YAML and transfer weights\n",
    "image_path = \"/vol/bitbucket/ajm223/SWE_GP/data/yoloDS3/val/images/\"\n",
    "image_files = os.listdir(image_path)\n",
    "img_paths = [image_path + image_files[i] for i in range(len(image_files))]\n",
    "\n",
    "\n",
    "def pack_results_for_eval(result, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Packs the results from the model into a format that can be used for evaluation\n",
    "    \"\"\"\n",
    "    \n",
    "    # boxes in xyhw format\n",
    "    packed_result = {}\n",
    "\n",
    "    packed_result[\"boxes\"] = result.boxes.xywh.to(device)\n",
    "\n",
    "    # scores\n",
    "    packed_result[\"scores\"] = result.boxes.conf.to(device)\n",
    "    packed_result[\"masks\"] = result.masks.data.to(torch.bool).to(device)\n",
    "\n",
    "    # class\n",
    "    packed_result[\"class\"] = result.boxes.cls.to(device)\n",
    "\n",
    "\n",
    "    return packed_result\n",
    "\n",
    "idx = \"CHANGE THIS\"\n",
    "idx = 0\n",
    "\n",
    "result = model(img_paths[idx])[0]\n",
    "packed_result = pack_results_for_eval(result, device=\"cpu\")\n",
    "print(packed_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pack_results_for_eval(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf = model2('test2.png',)\n",
    "inf[0].save(\"result2.jpg\")  # show results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search and Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Define parameter grid\n",
    "grid = {\n",
    "    'batch': [8, 16, 32],\n",
    "    'device': [0],\n",
    "    'project': [\"segment\"],\n",
    "    'seed': [42],\n",
    "    'rect': [False, True],\n",
    "    'cos_lr': [False, True],\n",
    "    'amp': [False, True],\n",
    "    'fraction': [0.8, 1.0],\n",
    "    'lr0': [0.01, 0.001, 0.0001],\n",
    "    'lrf': [0.01, 1, 0.1],\n",
    "    'momentum': [0.937, 0.949, 0.95],\n",
    "    'weight_decay': [0.0005, 0.01, 0.1],\n",
    "    'warmup_epochs': [0, 3],\n",
    "    'overlap_masks': [True, False],\n",
    "    'dropout': [0.0, 0.1, 0.2],\n",
    "    'val': [True],\n",
    "    'plots': [True],\n",
    "    'epochs': [300],\n",
    "    'patience': [50, 75, 300]\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_val_loss = float('inf')\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(grid):\n",
    "    model = YOLO('yolov8n-seg.pt')\n",
    "    results = model.train(\n",
    "        data=f'../../data/yoloDS{ts}/yoloDS{ts}.yaml',\n",
    "        epochs=params['epochs'],\n",
    "        imgsz=1000,\n",
    "        device=params['device'],\n",
    "        batch=params['batch'],\n",
    "        rect=params['rect'],\n",
    "        cos_lr=params['cos_lr'],\n",
    "        amp=params['amp'],\n",
    "        fraction=params['fraction'],\n",
    "        lr0=params['lr0'],\n",
    "        lrf=params['lrf'],\n",
    "        momentum=params['momentum'],\n",
    "        weight_decay=params['weight_decay'],\n",
    "        warmup_epochs=params['warmup_epochs'],\n",
    "        overlap_masks=params['overlap_masks'],\n",
    "        dropout=params['dropout'],\n",
    "        val=params['val'],\n",
    "        plots=params['plots']\n",
    "    )\n",
    "    val_loss = results[0]['val_loss']\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "        best_params = params\n",
    "\n",
    "print(f\"Best validation loss: {best_val_loss}\")\n",
    "print(f\"Best model parameters: {best_params}\")\n",
    "\n",
    "# Save the best model\n",
    "best_model.save('best_model.pt')\n",
    "\n",
    "# Save the best model parameters\n",
    "with open(\"best_model_params.json\", \"w\") as f:\n",
    "    json.dump(best_params, f)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
